{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "384e14ee259d4f60a23443b45acb1dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e94d68cfabe42a6bb792a7a5494557b",
              "IPY_MODEL_743f2039ecbe4a6e9c4bf09a7ff38ba5",
              "IPY_MODEL_a08af1c597e741b0b401ea82c63c5117"
            ],
            "layout": "IPY_MODEL_2ed6a3137777486fac0b7ab9406dc1d0"
          }
        },
        "6e94d68cfabe42a6bb792a7a5494557b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2065e359448d41c5873f6d7af26bbc18",
            "placeholder": "​",
            "style": "IPY_MODEL_f881a50c68b642aa9c2d087db34d9c57",
            "value": "100%"
          }
        },
        "743f2039ecbe4a6e9c4bf09a7ff38ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d8ab221f9949babb7248efe62cbe70",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a35c9dab45b045c2b135973ea37a0b3b",
            "value": 5
          }
        },
        "a08af1c597e741b0b401ea82c63c5117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac33324da65e466b98632302dc371d2c",
            "placeholder": "​",
            "style": "IPY_MODEL_d9fda10054614b32aaaa673d11f6d58f",
            "value": " 5/5 [00:01&lt;00:00,  2.77it/s]"
          }
        },
        "2ed6a3137777486fac0b7ab9406dc1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2065e359448d41c5873f6d7af26bbc18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f881a50c68b642aa9c2d087db34d9c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74d8ab221f9949babb7248efe62cbe70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35c9dab45b045c2b135973ea37a0b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac33324da65e466b98632302dc371d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fda10054614b32aaaa673d11f6d58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Step1. Install AI Gym, the instructions can be found at OpenAI-Lunar-LanderLinks to an external site."
      ],
      "metadata": {
        "id": "DfpAk7JSG2YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.10-venv\n",
        "!python3 -m venv env\n",
        "!source env/bin/activate\n",
        "!sudo apt-get install swig libpython3.10-dev\n",
        "!pip install box2d-py\n",
        "!pip install gym[box2d]==0.25.2\n",
        "! sudo apt-get install xvfb\n",
        "! pip install pyvirtualdisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOB6lAj80l40",
        "outputId": "500f8f8c-3440-4af0-c10a-60afaa0041e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,383 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,118 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,083 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,848 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,374 kB]\n",
            "Fetched 9,040 kB in 5s (1,968 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.3 [5,716 B]\n",
            "Fetched 2,473 kB in 1s (3,599 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.3_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libpython3.10-dev is already the newest version (3.10.12-1~22.04.3).\n",
            "libpython3.10-dev set to manually installed.\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (1,786 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121933 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting box2d-py\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp310-cp310-linux_x86_64.whl size=2349113 sha256=1eeb3e3cf4d4b37d09f6521d0023e15923df049db94fc0d21f860c655aff7459\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/01/d2/6a780da77ccb98b1d2facdd520a8d10838a03b590f6f8d50c0\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[box2d]==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d]==0.25.2)\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d]==0.25.2)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.* (from gym[box2d]==0.25.2)\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349140 sha256=2d6a7310765fb60828eb1acd27046e1c201a5ffafcd48d85c62342a9659cf779\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py, pygame\n",
            "  Attempting uninstall: box2d-py\n",
            "    Found existing installation: box2d-py 2.3.8\n",
            "    Uninstalling box2d-py-2.3.8:\n",
            "      Successfully uninstalled box2d-py-2.3.8\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.2.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 7,813 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 7,813 kB in 1s (9,344 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 122686 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step2. Import the environment"
      ],
      "metadata": {
        "id": "vqk8xdbJGyVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eRhqgWzpzwRq"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from gym import make\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "SEED = 21\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "GAMMA = 0.99\n",
        "TAU = 1e-3\n",
        "INITIAL_STEPS = 1024\n",
        "TRANSITIONS = 500_000\n",
        "STEPS_PER_UPDATE = 4\n",
        "STEPS_PER_TARGET_UPDATE = STEPS_PER_UPDATE * 1000\n",
        "BATCH_SIZE = 512\n",
        "LEARNING_RATE = 5e-4\n",
        "HIDDEN_DIMENSION = 64\n",
        "ENVIRONMENT_NAME = \"LunarLander-v2\"\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "def evaluate_policy(agent, episodes=5, verbose=False):\n",
        "    env = make(ENVIRONMENT_NAME)\n",
        "    returns = []\n",
        "    if verbose:\n",
        "        pbar = tqdm(total=episodes)\n",
        "    for _ in range(episodes):\n",
        "        done = False\n",
        "        state = env.reset()\n",
        "        total_reward = 0.0\n",
        "\n",
        "        while not done:\n",
        "            state, reward, done, *_ = env.step(agent.act(state))\n",
        "            total_reward += reward\n",
        "        returns.append(total_reward)\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(1)\n",
        "\n",
        "    return returns\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity=10_000, device=DEVICE):\n",
        "        self.capacity = capacity\n",
        "        self.num_stored = 0\n",
        "        self.next_index = 0\n",
        "        self.device = device\n",
        "\n",
        "        self.states = None\n",
        "        self.actions = None\n",
        "        self.next_states = None\n",
        "        self.rewards = None\n",
        "        self.dones = None\n",
        "\n",
        "    def is_sampleable(self, replay_size):\n",
        "        return replay_size <= self.num_stored\n",
        "\n",
        "    def add(self, state, action, next_state, reward, done):\n",
        "        state = torch.tensor(state)\n",
        "        next_state = torch.tensor(next_state)\n",
        "\n",
        "        if self.states is None:\n",
        "            state_shape = [self.capacity] + list(state.shape)\n",
        "            action_shape = [self.capacity]\n",
        "            next_state_shape = [self.capacity] + list(next_state.shape)\n",
        "            reward_shape = [self.capacity]\n",
        "            done_shape = [self.capacity]\n",
        "            self.states = torch.empty(state_shape, dtype=torch.float32, device=self.device)\n",
        "            self.actions = torch.empty(action_shape, dtype=torch.long, device=self.device)\n",
        "            self.next_states = torch.empty(next_state_shape, dtype=torch.float32, device=self.device)\n",
        "            self.rewards = torch.empty(reward_shape, dtype=torch.float32, device=self.device)\n",
        "            self.dones = torch.empty(done_shape, dtype=torch.long, device=self.device)\n",
        "\n",
        "        self.states[self.next_index] = state\n",
        "        self.actions[self.next_index] = action\n",
        "        self.next_states[self.next_index] = next_state\n",
        "        self.rewards[self.next_index] = reward\n",
        "        self.dones[self.next_index] = done\n",
        "\n",
        "        self.next_index = (self.next_index + 1) % self.capacity\n",
        "        self.num_stored = min(self.capacity, self.num_stored + 1)\n",
        "\n",
        "    def sample_batch(self, replay_size=BATCH_SIZE):\n",
        "        indexes = torch.randperm(self.num_stored)[:replay_size]\n",
        "        return (\n",
        "            self.states[indexes],\n",
        "            self.actions[indexes].view(-1, 1),\n",
        "            self.next_states[indexes],\n",
        "            self.rewards[indexes].view(-1, 1),\n",
        "            self.dones[indexes].view(-1, 1),\n",
        "        )\n",
        "\n",
        "# Deep Q-Network Model\n",
        "class DeepQNetworkModel(torch.nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=HIDDEN_DIMENSION):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, state):\n",
        "        h = self.activation(self.fc1(state))\n",
        "        h = self.activation(self.fc2(h))\n",
        "        out = self.fc3(h)\n",
        "        return out\n",
        "\n",
        "# DQN Agent\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=64):\n",
        "        self.steps = 0\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.buffer = ExperienceBuffer(10**5)\n",
        "        self.local_model = DeepQNetworkModel(state_dim, action_dim, hidden_dim).to(DEVICE)\n",
        "        self.target_model = DeepQNetworkModel(state_dim, action_dim, hidden_dim).to(DEVICE)\n",
        "        self.target_model.eval()\n",
        "        self.optimizer = Adam(self.local_model.parameters())\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def consume_transition(self, transition):\n",
        "        self.buffer.add(*transition)\n",
        "\n",
        "    def sample_batch(self):\n",
        "        return self.buffer.sample_batch()\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        states, actions, next_states, rewards, dones = batch\n",
        "\n",
        "        q_pred = self.local_model(states).gather(1, actions)\n",
        "        with torch.no_grad():\n",
        "            q_next = self.target_model(next_states).max(1)[0].unsqueeze(1)\n",
        "        q_target = rewards + GAMMA * q_next * (1 - dones)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.criterion(q_pred, q_target)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.soft_update_target_network()\n",
        "\n",
        "    def soft_update_target_network(self):\n",
        "        for target_param, local_param in zip(\n",
        "            self.target_model.parameters(), self.local_model.parameters()\n",
        "        ):\n",
        "            target_param.data.copy_(\n",
        "                TAU * local_param.data + (1.0 - TAU) * target_param.data\n",
        "            )\n",
        "\n",
        "    def update_target_network(self):\n",
        "        self.target_model = copy.deepcopy(self.local_model)\n",
        "\n",
        "    def act(self, state, target=False):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        self.local_model.eval()\n",
        "        with torch.no_grad():\n",
        "            action = np.argmax(self.local_model(state).cpu().numpy())\n",
        "        self.local_model.train()\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update(self, transition):\n",
        "        self.consume_transition(transition)\n",
        "        if self.steps % STEPS_PER_UPDATE == 0:\n",
        "            batch = self.sample_batch()\n",
        "            self.train_step(batch)\n",
        "        if self.steps % STEPS_PER_TARGET_UPDATE == 0:\n",
        "            self.update_target_network()\n",
        "        self.steps += 1\n",
        "\n",
        "    def save(self):\n",
        "        torch.save(self.local_model.state_dict(), \"agent.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3. Train a model"
      ],
      "metadata": {
        "id": "9ggtLg5ZGr_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Training\n",
        "set_seed(SEED)\n",
        "env = make(ENVIRONMENT_NAME)\n",
        "dqn_agent = DQNAgent(state_dim=env.observation_space.shape[0], action_dim=env.action_space.n, hidden_dim=HIDDEN_DIMENSION)\n",
        "dqn_agent.local_model.to(device)\n",
        "dqn_agent.target_model.to(device)\n",
        "eps = 0.1\n",
        "state = env.reset()\n",
        "\n",
        "for _ in range(INITIAL_STEPS):\n",
        "    action = env.action_space.sample()\n",
        "\n",
        "    next_state, reward, done, *_ = env.step(action)\n",
        "    dqn_agent.consume_transition((state, action, next_state, reward, done))\n",
        "\n",
        "    state = next_state if not done else env.reset()\n",
        "\n",
        "best_avg_rewards = -np.inf\n",
        "for i in range(TRANSITIONS):\n",
        "    # Epsilon-greedy policy\n",
        "    if random.random() < eps:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = dqn_agent.act(state)\n",
        "\n",
        "    next_state, reward, done, *_ = env.step(action)\n",
        "    dqn_agent.update((state, action, next_state, reward, done))\n",
        "\n",
        "    state = next_state if not done else env.reset()\n",
        "\n",
        "    if (i + 1) % (TRANSITIONS // 100) == 0:\n",
        "        rewards = evaluate_policy(dqn_agent, 5)\n",
        "        avg_reward = np.mean(rewards)\n",
        "        print(f\"Step: {i + 1}/{TRANSITIONS}, Best reward mean: {best_avg_rewards:.2f}, Reward mean: {avg_reward:.2f}, Reward std: {np.std(rewards):.2f}\")\n",
        "        if avg_reward > best_avg_rewards:\n",
        "            best_avg_rewards = avg_reward\n",
        "            dqn_agent.save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtYvzeiPzx_v",
        "outputId": "b8deed79-0873-4f87-acca-a30203763d54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 5000/500000, Best reward mean: -inf, Reward mean: -50.43, Reward std: 51.08\n",
            "Step: 10000/500000, Best reward mean: -50.43, Reward mean: -6.55, Reward std: 168.32\n",
            "Step: 15000/500000, Best reward mean: -6.55, Reward mean: -124.98, Reward std: 72.14\n",
            "Step: 20000/500000, Best reward mean: -6.55, Reward mean: -254.98, Reward std: 238.03\n",
            "Step: 25000/500000, Best reward mean: -6.55, Reward mean: -50.80, Reward std: 53.79\n",
            "Step: 30000/500000, Best reward mean: -6.55, Reward mean: -104.78, Reward std: 47.42\n",
            "Step: 35000/500000, Best reward mean: -6.55, Reward mean: -150.18, Reward std: 10.88\n",
            "Step: 40000/500000, Best reward mean: -6.55, Reward mean: -99.47, Reward std: 66.82\n",
            "Step: 45000/500000, Best reward mean: -6.55, Reward mean: -107.89, Reward std: 25.95\n",
            "Step: 50000/500000, Best reward mean: -6.55, Reward mean: -96.68, Reward std: 17.98\n",
            "Step: 55000/500000, Best reward mean: -6.55, Reward mean: -94.34, Reward std: 32.51\n",
            "Step: 60000/500000, Best reward mean: -6.55, Reward mean: -64.84, Reward std: 28.88\n",
            "Step: 65000/500000, Best reward mean: -6.55, Reward mean: -48.81, Reward std: 11.50\n",
            "Step: 70000/500000, Best reward mean: -6.55, Reward mean: -81.51, Reward std: 19.52\n",
            "Step: 75000/500000, Best reward mean: -6.55, Reward mean: -43.34, Reward std: 35.25\n",
            "Step: 80000/500000, Best reward mean: -6.55, Reward mean: 16.72, Reward std: 81.87\n",
            "Step: 85000/500000, Best reward mean: 16.72, Reward mean: -41.86, Reward std: 55.83\n",
            "Step: 90000/500000, Best reward mean: 16.72, Reward mean: 150.58, Reward std: 120.71\n",
            "Step: 95000/500000, Best reward mean: 150.58, Reward mean: -42.28, Reward std: 25.97\n",
            "Step: 100000/500000, Best reward mean: 150.58, Reward mean: -27.82, Reward std: 119.94\n",
            "Step: 105000/500000, Best reward mean: 150.58, Reward mean: -3.46, Reward std: 30.93\n",
            "Step: 110000/500000, Best reward mean: 150.58, Reward mean: 139.84, Reward std: 43.20\n",
            "Step: 115000/500000, Best reward mean: 150.58, Reward mean: 8.07, Reward std: 126.18\n",
            "Step: 120000/500000, Best reward mean: 150.58, Reward mean: 78.50, Reward std: 125.02\n",
            "Step: 125000/500000, Best reward mean: 150.58, Reward mean: 96.05, Reward std: 154.86\n",
            "Step: 130000/500000, Best reward mean: 150.58, Reward mean: 172.56, Reward std: 153.64\n",
            "Step: 135000/500000, Best reward mean: 172.56, Reward mean: 176.68, Reward std: 45.40\n",
            "Step: 140000/500000, Best reward mean: 176.68, Reward mean: 97.57, Reward std: 159.06\n",
            "Step: 145000/500000, Best reward mean: 176.68, Reward mean: 191.06, Reward std: 50.92\n",
            "Step: 150000/500000, Best reward mean: 191.06, Reward mean: 122.57, Reward std: 112.18\n",
            "Step: 155000/500000, Best reward mean: 191.06, Reward mean: 126.61, Reward std: 83.74\n",
            "Step: 160000/500000, Best reward mean: 191.06, Reward mean: 71.52, Reward std: 53.83\n",
            "Step: 165000/500000, Best reward mean: 191.06, Reward mean: 133.09, Reward std: 61.64\n",
            "Step: 170000/500000, Best reward mean: 191.06, Reward mean: 55.04, Reward std: 146.94\n",
            "Step: 175000/500000, Best reward mean: 191.06, Reward mean: 137.53, Reward std: 84.96\n",
            "Step: 180000/500000, Best reward mean: 191.06, Reward mean: 138.73, Reward std: 150.48\n",
            "Step: 185000/500000, Best reward mean: 191.06, Reward mean: 44.14, Reward std: 131.75\n",
            "Step: 190000/500000, Best reward mean: 191.06, Reward mean: 124.23, Reward std: 149.21\n",
            "Step: 195000/500000, Best reward mean: 191.06, Reward mean: 176.68, Reward std: 94.08\n",
            "Step: 200000/500000, Best reward mean: 191.06, Reward mean: 109.38, Reward std: 135.25\n",
            "Step: 205000/500000, Best reward mean: 191.06, Reward mean: 126.41, Reward std: 142.63\n",
            "Step: 210000/500000, Best reward mean: 191.06, Reward mean: 172.20, Reward std: 56.16\n",
            "Step: 215000/500000, Best reward mean: 191.06, Reward mean: -8.36, Reward std: 91.54\n",
            "Step: 220000/500000, Best reward mean: 191.06, Reward mean: 84.22, Reward std: 131.32\n",
            "Step: 225000/500000, Best reward mean: 191.06, Reward mean: 117.26, Reward std: 121.52\n",
            "Step: 230000/500000, Best reward mean: 191.06, Reward mean: 88.27, Reward std: 138.12\n",
            "Step: 235000/500000, Best reward mean: 191.06, Reward mean: 162.61, Reward std: 98.16\n",
            "Step: 240000/500000, Best reward mean: 191.06, Reward mean: 205.82, Reward std: 22.90\n",
            "Step: 245000/500000, Best reward mean: 205.82, Reward mean: 168.98, Reward std: 110.38\n",
            "Step: 250000/500000, Best reward mean: 205.82, Reward mean: 252.55, Reward std: 19.22\n",
            "Step: 255000/500000, Best reward mean: 252.55, Reward mean: 267.47, Reward std: 17.46\n",
            "Step: 260000/500000, Best reward mean: 267.47, Reward mean: 246.95, Reward std: 14.28\n",
            "Step: 265000/500000, Best reward mean: 267.47, Reward mean: 244.62, Reward std: 44.03\n",
            "Step: 270000/500000, Best reward mean: 267.47, Reward mean: 218.82, Reward std: 20.95\n",
            "Step: 275000/500000, Best reward mean: 267.47, Reward mean: 247.12, Reward std: 23.57\n",
            "Step: 280000/500000, Best reward mean: 267.47, Reward mean: 254.90, Reward std: 29.60\n",
            "Step: 285000/500000, Best reward mean: 267.47, Reward mean: 254.02, Reward std: 10.64\n",
            "Step: 290000/500000, Best reward mean: 267.47, Reward mean: 253.20, Reward std: 19.80\n",
            "Step: 295000/500000, Best reward mean: 267.47, Reward mean: 274.18, Reward std: 8.99\n",
            "Step: 300000/500000, Best reward mean: 274.18, Reward mean: 213.57, Reward std: 55.39\n",
            "Step: 305000/500000, Best reward mean: 274.18, Reward mean: 260.52, Reward std: 14.26\n",
            "Step: 310000/500000, Best reward mean: 274.18, Reward mean: 167.46, Reward std: 126.53\n",
            "Step: 315000/500000, Best reward mean: 274.18, Reward mean: 197.58, Reward std: 88.39\n",
            "Step: 320000/500000, Best reward mean: 274.18, Reward mean: 264.50, Reward std: 37.71\n",
            "Step: 325000/500000, Best reward mean: 274.18, Reward mean: 195.70, Reward std: 110.58\n",
            "Step: 330000/500000, Best reward mean: 274.18, Reward mean: 166.91, Reward std: 106.01\n",
            "Step: 335000/500000, Best reward mean: 274.18, Reward mean: 241.22, Reward std: 62.99\n",
            "Step: 340000/500000, Best reward mean: 274.18, Reward mean: 252.91, Reward std: 21.76\n",
            "Step: 345000/500000, Best reward mean: 274.18, Reward mean: 233.51, Reward std: 41.70\n",
            "Step: 350000/500000, Best reward mean: 274.18, Reward mean: 212.94, Reward std: 53.71\n",
            "Step: 355000/500000, Best reward mean: 274.18, Reward mean: 259.49, Reward std: 25.91\n",
            "Step: 360000/500000, Best reward mean: 274.18, Reward mean: 186.31, Reward std: 82.63\n",
            "Step: 365000/500000, Best reward mean: 274.18, Reward mean: 220.36, Reward std: 51.37\n",
            "Step: 370000/500000, Best reward mean: 274.18, Reward mean: 221.40, Reward std: 43.70\n",
            "Step: 375000/500000, Best reward mean: 274.18, Reward mean: 223.96, Reward std: 60.59\n",
            "Step: 380000/500000, Best reward mean: 274.18, Reward mean: 253.15, Reward std: 28.39\n",
            "Step: 385000/500000, Best reward mean: 274.18, Reward mean: 230.80, Reward std: 48.29\n",
            "Step: 390000/500000, Best reward mean: 274.18, Reward mean: 183.71, Reward std: 58.50\n",
            "Step: 395000/500000, Best reward mean: 274.18, Reward mean: 263.82, Reward std: 18.13\n",
            "Step: 400000/500000, Best reward mean: 274.18, Reward mean: 262.03, Reward std: 16.73\n",
            "Step: 405000/500000, Best reward mean: 274.18, Reward mean: 238.58, Reward std: 43.06\n",
            "Step: 410000/500000, Best reward mean: 274.18, Reward mean: 254.08, Reward std: 23.13\n",
            "Step: 415000/500000, Best reward mean: 274.18, Reward mean: 203.80, Reward std: 69.37\n",
            "Step: 420000/500000, Best reward mean: 274.18, Reward mean: 204.82, Reward std: 48.87\n",
            "Step: 425000/500000, Best reward mean: 274.18, Reward mean: 272.74, Reward std: 16.07\n",
            "Step: 430000/500000, Best reward mean: 274.18, Reward mean: 256.12, Reward std: 13.53\n",
            "Step: 435000/500000, Best reward mean: 274.18, Reward mean: 248.20, Reward std: 24.33\n",
            "Step: 440000/500000, Best reward mean: 274.18, Reward mean: 264.98, Reward std: 20.17\n",
            "Step: 445000/500000, Best reward mean: 274.18, Reward mean: 269.45, Reward std: 23.61\n",
            "Step: 450000/500000, Best reward mean: 274.18, Reward mean: 221.02, Reward std: 52.02\n",
            "Step: 455000/500000, Best reward mean: 274.18, Reward mean: 277.91, Reward std: 7.97\n",
            "Step: 460000/500000, Best reward mean: 277.91, Reward mean: 266.85, Reward std: 19.12\n",
            "Step: 465000/500000, Best reward mean: 277.91, Reward mean: 245.34, Reward std: 48.72\n",
            "Step: 470000/500000, Best reward mean: 277.91, Reward mean: 272.03, Reward std: 13.96\n",
            "Step: 475000/500000, Best reward mean: 277.91, Reward mean: 276.22, Reward std: 16.11\n",
            "Step: 480000/500000, Best reward mean: 277.91, Reward mean: 268.62, Reward std: 17.79\n",
            "Step: 485000/500000, Best reward mean: 277.91, Reward mean: 261.67, Reward std: 11.83\n",
            "Step: 490000/500000, Best reward mean: 277.91, Reward mean: 261.33, Reward std: 14.03\n",
            "Step: 495000/500000, Best reward mean: 277.91, Reward mean: 245.16, Reward std: 37.38\n",
            "Step: 500000/500000, Best reward mean: 277.91, Reward mean: 275.81, Reward std: 13.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "class TrainedAgent:\n",
        "    def __init__(self, weights=\"agent.pth\"):\n",
        "        self.model = DeepQNetworkModel(8, 4, HIDDEN_DIMENSION)\n",
        "        weights = torch.load(weights, map_location=DEVICE)\n",
        "        self.model.load_state_dict(weights)\n",
        "        self.model.to(DEVICE)\n",
        "        self.model.eval()\n",
        "\n",
        "    def act(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            action = np.argmax(self.model(state).cpu().numpy())\n",
        "        return action\n",
        "\n",
        "trained_agent = TrainedAgent(\"agent.pth\")\n",
        "rewards = evaluate_policy(trained_agent, 5, True)\n",
        "print(\"Average reward on 5 episodes:\", np.mean(rewards))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "384e14ee259d4f60a23443b45acb1dfa",
            "6e94d68cfabe42a6bb792a7a5494557b",
            "743f2039ecbe4a6e9c4bf09a7ff38ba5",
            "a08af1c597e741b0b401ea82c63c5117",
            "2ed6a3137777486fac0b7ab9406dc1d0",
            "2065e359448d41c5873f6d7af26bbc18",
            "f881a50c68b642aa9c2d087db34d9c57",
            "74d8ab221f9949babb7248efe62cbe70",
            "a35c9dab45b045c2b135973ea37a0b3b",
            "ac33324da65e466b98632302dc371d2c",
            "d9fda10054614b32aaaa673d11f6d58f"
          ]
        },
        "id": "pdpqioMW0F4a",
        "outputId": "b4f48966-a59f-4eb9-8a40-353e2e04bbf9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "384e14ee259d4f60a23443b45acb1dfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward on 5 episodes: 245.03502156354642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step5. Play an episode of the problem using your agent."
      ],
      "metadata": {
        "id": "lY0hyHtOGoqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rendering and displaying video\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from gym.wrappers.monitoring import video_recorder\n",
        "from IPython import display\n",
        "from IPython.display import FileLink\n",
        "\n",
        "def show_video(env_name, video_dir=\".\"):\n",
        "    mp4list = glob.glob(f'{video_dir}/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = f'{video_dir}/{env_name}.mp4'\n",
        "        video = io.open(mp4, 'rb').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display.display(display.HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "        display.display(FileLink(mp4, result_html_prefix=\"Click here to download: \"))\n",
        "    else:\n",
        "        print(\"Could not find video\")\n",
        "\n",
        "def render_video_of_model(agent, env_name):\n",
        "    env = make(env_name)\n",
        "    vid = video_recorder.VideoRecorder(env, path=f\"{env_name}.mp4\")\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        vid.capture_frame()\n",
        "\n",
        "        action = agent.act(state)\n",
        "\n",
        "        state, reward, done, _ = env.step(action)\n",
        "    env.close()\n",
        "\n",
        "render_video_of_model(trained_agent, ENVIRONMENT_NAME)\n",
        "show_video(ENVIRONMENT_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "VX-kuSra0IHb",
        "outputId": "b6042453-aa33-48da-9b99-da415a437e6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment LunarLander-v2 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:101: DeprecationWarning: \u001b[33mWARN: <class 'gym.wrappers.monitoring.video_recorder.VideoRecorder'> is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video alt=\"test\" autoplay\n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/LunarLander-v2.mp4"
            ],
            "text/html": [
              "Click here to download: <a href='./LunarLander-v2.mp4' target='_blank'>./LunarLander-v2.mp4</a><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4. Discuss the parameters used to produce your training results\n",
        "\n",
        "The parameters used for training the Deep Q-Network (DQN) agent are as follows:\n",
        "```\n",
        "SEED = 21\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "GAMMA = 0.99\n",
        "TAU = 1e-3\n",
        "INITIAL_STEPS = 1024\n",
        "TRANSITIONS = 500_000\n",
        "STEPS_PER_UPDATE = 4\n",
        "STEPS_PER_TARGET_UPDATE = STEPS_PER_UPDATE * 1000\n",
        "BATCH_SIZE = 512\n",
        "LEARNING_RATE = 5e-4\n",
        "HIDDEN_DIMENSION = 64\n",
        "ENVIRONMENT_NAME = \"LunarLander-v2\"\n",
        "```\n",
        "SEED: The random seed used for reproducibility. We have used a seed of 21 to repreduce the same steps for training.\n",
        "\n",
        "GAMMA: The discount factor for future rewards. We have used 0.99 as the discount factor.\n",
        "\n",
        "TAU: The parameter for soft update of target network weights. Value of 1e-3 is used here.\n",
        "\n",
        "INITIAL_STEPS: The number of initial steps taken by the agent to populate the experience buffer. The model takes 1024 steps to populate the experience buffer.\n",
        "\n",
        "TRANSITIONS: The total number of transitions (steps) taken during training. We take 500000 steps to train.\n",
        "\n",
        "STEPS_PER_UPDATE: The number of steps between each update of the local network. We use 4 steps per update.\n",
        "\n",
        "STEPS_PER_TARGET_UPDATE: The number of steps between each update of the target network.\n",
        "\n",
        "BATCH_SIZE: The size of the mini-batch used for training. We take 512 as a batch size to speed up the training.\n",
        "\n",
        "LEARNING_RATE: The learning rate used by the Adam optimizer. We use 5e-4 as value.\n",
        "\n",
        "HIDDEN_DIMENSION: The dimension of the hidden layers in the neural network. We use a dimension of 64."
      ],
      "metadata": {
        "id": "dgR164-uE_-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6. Discuss the results in terms of success rate\n",
        "\n",
        "The training results show improvement in terms of the average reward mean over time, with occasional fluctuations. The best reward mean achieved during training was around 277.91.\n",
        "\n",
        "Average reward on 5 episodes that were used for evaluation is: 245.03502156354642\n",
        "\n",
        "From the video, we can see that the lander lands properly on the target.\n",
        "\n"
      ],
      "metadata": {
        "id": "9vFnng-5GCX8"
      }
    }
  ]
}